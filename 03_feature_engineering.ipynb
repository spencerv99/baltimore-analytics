{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baltimore Analytics \u2014 Feature Engineering\n",
    "**Project:** `baltimore-analytics`  \n",
    "**Input:** `analytics` dataset  \n",
    "**Output:** `analytics.neighborhood_features` (feature matrix)  \n",
    "**Author:** Spencer  \n",
    "\n",
    "---\n",
    "### What This Notebook Does\n",
    "Aggregates all spatially enriched tables to the **neighborhood (NSA) level** and builds a single\n",
    "feature matrix suitable for clustering and Looker Studio dashboards.\n",
    "\n",
    "```\n",
    "analytics.crime_incidents_legacy    \u2500\u2510\n",
    "analytics.crime_incidents_current   \u2500\u2524\n",
    "analytics.bpd_arrests               \u2500\u2524\n",
    "analytics.vacant_building_notices   \u2500\u2524\u2192  analytics.neighborhood_features\n",
    "analytics.vacant_building_rehabs    \u2500\u2524\n",
    "analytics.building_permits          \u2500\u2524\n",
    "analytics.service_requests_311      \u2500\u2524\n",
    "analytics.real_property             \u2500\u2518\n",
    "```\n",
    "\n",
    "### Feature Groups\n",
    "| Group | Features |\n",
    "|---|---|\n",
    "| **Demographics** | Population, age distribution, race/ethnicity, household composition |\n",
    "| **Public Safety** | Crime rate, arrest rate, crime trend (YoY) |\n",
    "| **Housing** | Vacancy rate, rehab activity, building permit investment |\n",
    "| **Quality of Life** | 311 request volume, request types |\n",
    "| **Property** | Median assessed value, owner vs renter ratio |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s \u2014 %(levelname)s \u2014 %(message)s')\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "GCP_PROJECT       = \"baltimore-analytics\"\n",
    "ANALYTICS_DATASET = \"analytics\"\n",
    "GCP_REGION        = \"us-east1\"\n",
    "CREDENTIALS_PATH  = \"service_account.json\"\n",
    "\n",
    "# Reference years for trend analysis\n",
    "CURRENT_YEAR  = 2024\n",
    "BASELINE_YEAR = 2019  # Pre-COVID baseline\n",
    "\n",
    "print(f\"\u2713 Config loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    CREDENTIALS_PATH,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "bq = bigquery.Client(project=GCP_PROJECT, credentials=credentials)\n",
    "log.info(f\"\u2713 BigQuery client ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-Flight Check\n",
    "Verify all `analytics` tables exist before building features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_TABLES = [\n",
    "    \"crime_incidents_legacy\",\n",
    "    \"crime_incidents_current\",\n",
    "    \"bpd_arrests\",\n",
    "    \"vacant_building_notices\",\n",
    "    \"vacant_building_rehabs\",\n",
    "    \"building_permits\",\n",
    "    \"service_requests_311\",\n",
    "    \"real_property\",\n",
    "    \"neighborhood_boundaries\",\n",
    "]\n",
    "\n",
    "all_ok = True\n",
    "for table in REQUIRED_TABLES:\n",
    "    try:\n",
    "        t = bq.get_table(f\"{GCP_PROJECT}.{ANALYTICS_DATASET}.{table}\")\n",
    "        print(f\"\u2705 {table}: {t.num_rows:,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c {table}: missing\")\n",
    "        all_ok = False\n",
    "\n",
    "print(f\"\\n{'\u2713 All tables present.' if all_ok else '\u2717 Fix missing tables before proceeding.'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper \u2014 Run and Write Query\n",
    "Utility to run a SQL query and write result to `analytics` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_write(sql: str, dest_table: str, description: str = \"\") -> int:\n",
    "    \"\"\"Run a SQL query and write result to analytics dataset. Returns row count.\"\"\"\n",
    "    dest = f\"{GCP_PROJECT}.{ANALYTICS_DATASET}.{dest_table}\"\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        destination=dest,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "        create_disposition=bigquery.CreateDisposition.CREATE_IF_NEEDED,\n",
    "    )\n",
    "    log.info(f\"Building: {dest_table}{' \u2014 ' + description if description else ''}\")\n",
    "    bq.query(sql, job_config=job_config).result()\n",
    "    rows = bq.get_table(dest).num_rows\n",
    "    log.info(f\"  \u2713 {rows:,} rows \u2192 {dest}\")\n",
    "    return rows\n",
    "\n",
    "print(\"\u2713 Helper defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Intermediate Feature Tables\n",
    "Each section aggregates one source table to neighborhood level.  \n",
    "Results are written to intermediate tables in `analytics`, then joined in Cell 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 4.1 CRIME FEATURES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# Combines legacy (pre-2021) and current (post-2021) into unified crime counts\n",
    "run_and_write(f\"\"\"\n",
    "    WITH combined AS (\n",
    "        SELECT neighborhood, crimedatetime, description\n",
    "        FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.crime_incidents_legacy`\n",
    "        WHERE neighborhood IS NOT NULL\n",
    "        UNION ALL\n",
    "        SELECT neighborhood, crimedatetime, description\n",
    "        FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.crime_incidents_current`\n",
    "        WHERE neighborhood IS NOT NULL\n",
    "    )\n",
    "    SELECT\n",
    "        neighborhood,\n",
    "        COUNT(*) AS crime_total,\n",
    "        COUNTIF(EXTRACT(YEAR FROM crimedatetime) = {CURRENT_YEAR})  AS crime_{CURRENT_YEAR},\n",
    "        COUNTIF(EXTRACT(YEAR FROM crimedatetime) = {BASELINE_YEAR}) AS crime_{BASELINE_YEAR},\n",
    "        COUNTIF(EXTRACT(YEAR FROM crimedatetime) >= 2021)            AS crime_post2021,\n",
    "        COUNTIF(EXTRACT(YEAR FROM crimedatetime) <  2021)            AS crime_pre2021,\n",
    "        -- Top crime type\n",
    "        APPROX_TOP_COUNT(description, 1)[OFFSET(0)].value           AS top_crime_type,\n",
    "        -- YoY trend: positive = increasing crime\n",
    "        SAFE_DIVIDE(\n",
    "            COUNTIF(EXTRACT(YEAR FROM crimedatetime) = {CURRENT_YEAR}) -\n",
    "            COUNTIF(EXTRACT(YEAR FROM crimedatetime) = {CURRENT_YEAR} - 1),\n",
    "            NULLIF(COUNTIF(EXTRACT(YEAR FROM crimedatetime) = {CURRENT_YEAR} - 1), 0)\n",
    "        ) AS crime_yoy_change\n",
    "    FROM combined\n",
    "    GROUP BY neighborhood\n",
    "\"\"\", \"_feat_crime\", \"crime aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 4.2 ARREST FEATURES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "run_and_write(f\"\"\"\n",
    "    SELECT\n",
    "        neighborhood,\n",
    "        COUNT(*) AS arrest_total,\n",
    "        COUNTIF(EXTRACT(YEAR FROM arrestdatetime) = {CURRENT_YEAR})  AS arrest_{CURRENT_YEAR},\n",
    "        COUNTIF(EXTRACT(YEAR FROM arrestdatetime) = {BASELINE_YEAR}) AS arrest_{BASELINE_YEAR},\n",
    "        APPROX_TOP_COUNT(chargedescription, 1)[OFFSET(0)].value      AS top_arrest_charge\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.bpd_arrests`\n",
    "    WHERE neighborhood IS NOT NULL\n",
    "    GROUP BY neighborhood\n",
    "\"\"\", \"_feat_arrests\", \"arrest aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 4.3 VACANCY FEATURES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "run_and_write(f\"\"\"\n",
    "    SELECT\n",
    "        n.neighborhood,\n",
    "        COUNT(DISTINCT v.objectid)                                     AS vacant_notice_count,\n",
    "        COUNT(DISTINCT r.objectid)                                     AS rehab_permit_count,\n",
    "        SAFE_DIVIDE(COUNT(DISTINCT r.objectid), COUNT(DISTINCT v.objectid)) AS rehab_to_vacant_ratio\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.vacant_building_notices` v\n",
    "    FULL OUTER JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}.vacant_building_rehabs` r\n",
    "        USING (neighborhood)\n",
    "    RIGHT JOIN (SELECT DISTINCT neighborhood FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_boundaries`) n\n",
    "        USING (neighborhood)\n",
    "    WHERE n.neighborhood IS NOT NULL\n",
    "    GROUP BY n.neighborhood\n",
    "\"\"\", \"_feat_vacancy\", \"vacancy aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 4.4 BUILDING PERMIT FEATURES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "run_and_write(f\"\"\"\n",
    "    SELECT\n",
    "        neighborhood,\n",
    "        COUNT(*)                                                        AS permit_total,\n",
    "        COUNTIF(EXTRACT(YEAR FROM issueddate) >= 2020)                  AS permit_recent_5yr,\n",
    "        COUNTIF(EXTRACT(YEAR FROM issueddate) = {CURRENT_YEAR})         AS permit_{CURRENT_YEAR},\n",
    "        SUM(CAST(estimatedcost AS FLOAT64))                             AS permit_total_value,\n",
    "        AVG(CAST(estimatedcost AS FLOAT64))                             AS permit_avg_value\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.building_permits`\n",
    "    WHERE neighborhood IS NOT NULL\n",
    "    GROUP BY neighborhood\n",
    "\"\"\", \"_feat_permits\", \"building permit aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 4.5 311 SERVICE REQUEST FEATURES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "run_and_write(f\"\"\"\n",
    "    SELECT\n",
    "        neighborhood,\n",
    "        COUNT(*)                                                                AS requests_311_total,\n",
    "        COUNTIF(EXTRACT(YEAR FROM createddate) = {CURRENT_YEAR})                AS requests_311_{CURRENT_YEAR},\n",
    "        COUNTIF(EXTRACT(YEAR FROM createddate) = {BASELINE_YEAR})               AS requests_311_{BASELINE_YEAR},\n",
    "        APPROX_TOP_COUNT(servicerequesttype, 1)[OFFSET(0)].value                AS top_311_request_type,\n",
    "        COUNTIF(LOWER(servicerequesttype) LIKE '%abandon%'\n",
    "             OR LOWER(servicerequesttype) LIKE '%vacant%')                      AS requests_311_blight\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.service_requests_311`\n",
    "    WHERE neighborhood IS NOT NULL\n",
    "    GROUP BY neighborhood\n",
    "\"\"\", \"_feat_311\", \"311 aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 4.6 REAL PROPERTY FEATURES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# Note: real_property stores parcel polygons (not points) \u2014 we derive centroids\n",
    "# at query time using ST_CENTROID(ST_GEOGFROMTEXT(..., make_valid => TRUE))\n",
    "# to handle duplicate vertices in some parcel geometries.\n",
    "# Assessed value = currland + currimpr (fullcash is 0 for 93% of parcels)\n",
    "run_and_write(f\"\"\"\n",
    "    SELECT\n",
    "        n.name                                                                              AS neighborhood,\n",
    "        COUNT(*)                                                                            AS parcel_count,\n",
    "        APPROX_QUANTILES(CAST(p.currland AS FLOAT64) + CAST(p.currimpr AS FLOAT64), 2)[OFFSET(1)] AS median_assessed_value,\n",
    "        AVG(CAST(p.currland AS FLOAT64) + CAST(p.currimpr AS FLOAT64))                    AS avg_assessed_value,\n",
    "        SUM(CAST(p.currland AS FLOAT64) + CAST(p.currimpr AS FLOAT64))                    AS total_assessed_value,\n",
    "        COUNTIF(LOWER(p.usegroup) LIKE '%residential%')                                   AS residential_parcels,\n",
    "        COUNTIF(LOWER(p.usegroup) LIKE '%commercial%')                                    AS commercial_parcels\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.real_property` p\n",
    "    JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_boundaries` n\n",
    "      ON ST_WITHIN(\n",
    "           ST_CENTROID(ST_GEOGFROMTEXT(p.geo_polygon_wkt, make_valid => TRUE)),\n",
    "           n.geo_polygon_wkt\n",
    "         )\n",
    "    WHERE p.geo_polygon_wkt IS NOT NULL\n",
    "    GROUP BY n.name\n",
    "\"\"\", \"_feat_property\", \"real property aggregation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Master Feature Matrix\n",
    "Join all intermediate feature tables to `neighborhood_boundaries` as the spine.  \n",
    "Every neighborhood gets a row \u2014 features are NULL if no data exists for that neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_write(f\"\"\"\n",
    "    SELECT\n",
    "        -- \u2500\u2500 IDENTITY \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        nb.name                             AS neighborhood,\n",
    "        nb.objectid                         AS nsa_objectid,\n",
    "\n",
    "        -- \u2500\u2500 DEMOGRAPHICS (from neighborhood_boundaries) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        nb.population,\n",
    "        nb.white,\n",
    "        nb.blk_afam,\n",
    "        nb.hisp_lat,\n",
    "        nb.asian,\n",
    "        nb.med_age,\n",
    "        nb.total_units,\n",
    "        nb.occ_vacant,\n",
    "        SAFE_DIVIDE(nb.occ_vacant, nb.total_units)   AS housing_vacancy_rate,\n",
    "        SAFE_DIVIDE(nb.tenure_owner, nb.hh_total)    AS owner_occupancy_rate,\n",
    "        SAFE_DIVIDE(nb.tenure_renter, nb.hh_total)   AS renter_occupancy_rate,\n",
    "\n",
    "        -- \u2500\u2500 CRIME \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        COALESCE(cr.crime_total, 0)                  AS crime_total,\n",
    "        COALESCE(cr.crime_{CURRENT_YEAR}, 0)         AS crime_{CURRENT_YEAR},\n",
    "        COALESCE(cr.crime_{BASELINE_YEAR}, 0)        AS crime_{BASELINE_YEAR},\n",
    "        cr.crime_yoy_change,\n",
    "        cr.top_crime_type,\n",
    "        SAFE_DIVIDE(cr.crime_total, nb.population)   AS crime_per_capita,\n",
    "\n",
    "        -- \u2500\u2500 ARRESTS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        COALESCE(ar.arrest_total, 0)                 AS arrest_total,\n",
    "        COALESCE(ar.arrest_{CURRENT_YEAR}, 0)        AS arrest_{CURRENT_YEAR},\n",
    "        ar.top_arrest_charge,\n",
    "        SAFE_DIVIDE(ar.arrest_total, nb.population)  AS arrest_per_capita,\n",
    "\n",
    "        -- \u2500\u2500 VACANCY \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        COALESCE(va.vacant_notice_count, 0)          AS vacant_notice_count,\n",
    "        COALESCE(va.rehab_permit_count, 0)           AS rehab_permit_count,\n",
    "        va.rehab_to_vacant_ratio,\n",
    "        SAFE_DIVIDE(va.vacant_notice_count, nb.total_units) AS vacant_notices_per_unit,\n",
    "\n",
    "        -- \u2500\u2500 BUILDING PERMITS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        COALESCE(bp.permit_total, 0)                 AS permit_total,\n",
    "        COALESCE(bp.permit_recent_5yr, 0)            AS permit_recent_5yr,\n",
    "        bp.permit_total_value,\n",
    "        bp.permit_avg_value,\n",
    "        SAFE_DIVIDE(bp.permit_total_value, nb.population) AS permit_value_per_capita,\n",
    "\n",
    "        -- \u2500\u2500 311 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        COALESCE(sr.requests_311_total, 0)           AS requests_311_total,\n",
    "        COALESCE(sr.requests_311_{CURRENT_YEAR}, 0)  AS requests_311_{CURRENT_YEAR},\n",
    "        sr.top_311_request_type,\n",
    "        COALESCE(sr.requests_311_blight, 0)          AS requests_311_blight,\n",
    "        SAFE_DIVIDE(sr.requests_311_total, nb.population) AS requests_311_per_capita,\n",
    "\n",
    "        -- \u2500\u2500 PROPERTY VALUES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        pr.parcel_count,\n",
    "        pr.median_assessed_value,\n",
    "        pr.avg_assessed_value,\n",
    "        pr.total_assessed_value,\n",
    "        pr.residential_parcels,\n",
    "        pr.commercial_parcels,\n",
    "\n",
    "        -- \u2500\u2500 METADATA \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        '{datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}' AS _feature_built_at\n",
    "\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_boundaries` nb\n",
    "    LEFT JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}._feat_crime`    cr ON nb.name = cr.neighborhood\n",
    "    LEFT JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}._feat_arrests`  ar ON nb.name = ar.neighborhood\n",
    "    LEFT JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}._feat_vacancy`  va ON nb.name = va.neighborhood\n",
    "    LEFT JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}._feat_permits`  bp ON nb.name = bp.neighborhood\n",
    "    LEFT JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}._feat_311`      sr ON nb.name = sr.neighborhood\n",
    "    LEFT JOIN `{GCP_PROJECT}.{ANALYTICS_DATASET}._feat_property` pr ON nb.name = pr.neighborhood\n",
    "\"\"\", \"neighborhood_features\", \"master feature matrix\")\n",
    "\n",
    "print(\"\\n\u2713 neighborhood_features table built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row count \u2014 should be 279 (one per neighborhood)\nt = bq.get_table(f\"{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_features\")\nprint(f\"Rows: {t.num_rows} (expected 279)\")\nprint(f\"Columns: {len(t.schema)}\")\nprint()\n\n# Null rates per feature \u2014 flag anything unexpectedly sparse\ncols = [f.name for f in t.schema if f.field_type in ('FLOAT64', 'INT64', 'FLOAT', 'INTEGER')]\nnull_checks = \",\\n\".join([f\"ROUND(COUNTIF({c} IS NULL) / COUNT(*) * 100, 1) AS {c}_null_pct\" for c in cols[:20]])\n\nresult = bq.query(f\"\"\"\n    SELECT {null_checks}\n    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_features`\n\"\"\").to_dataframe()\n\nnull_summary = result.T.rename(columns={0: 'null_pct'}).sort_values('null_pct', ascending=False)\nprint(\"Null rates for numeric features:\")\ndisplay(null_summary[null_summary['null_pct'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample top 10 neighborhoods by crime per capita\n",
    "print(\"Top 10 neighborhoods by crime per capita:\")\n",
    "display(bq.query(f\"\"\"\n",
    "    SELECT\n",
    "        neighborhood,\n",
    "        population,\n",
    "        crime_total,\n",
    "        ROUND(crime_per_capita, 4)      AS crime_per_capita,\n",
    "        vacant_notice_count,\n",
    "        ROUND(median_assessed_value, 0) AS median_assessed_value\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_features`\n",
    "    WHERE population > 100  -- exclude parks/industrial areas\n",
    "    ORDER BY crime_per_capita DESC\n",
    "    LIMIT 10\n",
    "\"\"\").to_dataframe())\n",
    "\n",
    "# Sample top 10 neighborhoods by investment (permit value per capita)\n",
    "print(\"\\nTop 10 neighborhoods by permit investment per capita:\")\n",
    "display(bq.query(f\"\"\"\n",
    "    SELECT\n",
    "        neighborhood,\n",
    "        population,\n",
    "        permit_total,\n",
    "        ROUND(permit_value_per_capita, 0) AS permit_value_per_capita,\n",
    "        ROUND(median_assessed_value, 0)   AS median_assessed_value\n",
    "    FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_features`\n",
    "    WHERE population > 100\n",
    "    ORDER BY permit_value_per_capita DESC\n",
    "    LIMIT 10\n",
    "\"\"\").to_dataframe())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Feature Matrix for Clustering\n",
    "Pull `neighborhood_features` into a pandas DataFrame for use in notebook 04.  \n",
    "Saves a local CSV as a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = bq.query(f\"\"\"\n",
    "    SELECT * FROM `{GCP_PROJECT}.{ANALYTICS_DATASET}.neighborhood_features`\n",
    "    ORDER BY neighborhood\n",
    "\"\"\").to_dataframe()\n",
    "\n",
    "features_df.to_csv(\"neighborhood_features.csv\", index=False)\n",
    "\n",
    "print(f\"\u2713 Exported {len(features_df)} rows \u00d7 {len(features_df.columns)} columns\")\n",
    "print(f\"  Saved to: neighborhood_features.csv\")\n",
    "print(f\"\\nNumeric features available for clustering:\")\n",
    "numeric_cols = features_df.select_dtypes(include='number').columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **`04_clustering.ipynb`** \u2014 K-means segmentation using `neighborhood_features`\n",
    "2. **`05_looker_studio.md`** \u2014 Connect `analytics.neighborhood_features` to Looker Studio\n",
    "\n",
    "**Notes on feature quality:**\n",
    "- `bpd_arrests`: ~43% of records missing geo \u2192 arrest features undercount for older records\n",
    "- `service_requests_311`: 2023-2026 excluded from source data\n",
    "- `real_property`: `assessedvalue` may be NULL for some parcels \u2014 coerced to FLOAT64\n",
    "- Neighborhoods with `population < 100` are likely parks/industrial areas \u2014 consider excluding from clustering\n",
    "\n",
    "**If intermediate tables need to be rebuilt individually:**\n",
    "```python\n",
    "# Re-run just one intermediate table\n",
    "# Then re-run Cell 5 to rebuild the master matrix\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}